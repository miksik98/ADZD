{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gm9aYzTDTTU"
   },
   "source": [
    "# Spark MLlib Exercises\n",
    "\n",
    "\n",
    "http://spark.apache.org/docs/latest/ml-statistics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBM19ZBQDTTX"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "u1Z_Q8lZDTTZ",
    "outputId": "a1491224-f7c1-4336-e3d5-f1e11b1cfb95",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a2498837ad56:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbfa58a3990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7GDDu-2DTTa"
   },
   "source": [
    "## 1. Statistics (1p.)\n",
    "\n",
    "Download the following dataset: https://www.kaggle.com/c/titanic/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwIzAVYsGkEC",
    "outputId": "890b1285-c40d-45d7-9b77-69f55c5018ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|      Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----------+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|        C85|       C|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|  113803|   53.1|       C123|       S|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|   17463|51.8625|        E46|       S|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1| PP 9549|   16.7|         G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  113783|  26.55|       C103|       S|\n",
      "|         22|       1|     2|Beesley, Mr. Lawr...|  male|34.0|    0|    0|  248698|   13.0|        D56|       S|\n",
      "|         24|       1|     1|Sloper, Mr. Willi...|  male|28.0|    0|    0|  113788|   35.5|         A6|       S|\n",
      "|         28|       0|     1|Fortune, Mr. Char...|  male|19.0|    3|    2|   19950|  263.0|C23 C25 C27|       S|\n",
      "|         53|       1|     1|Harper, Mrs. Henr...|female|49.0|    1|    0|PC 17572|76.7292|        D33|       C|\n",
      "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|  113509|61.9792|        B30|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[('PassengerId', 'int'), ('Survived', 'int'), ('Pclass', 'int'), ('Name', 'string'), ('Sex', 'string'), ('Age', 'double'), ('SibSp', 'int'), ('Parch', 'int'), ('Ticket', 'string'), ('Fare', 'double'), ('Cabin', 'string'), ('Embarked', 'string')]\n"
     ]
    }
   ],
   "source": [
    "file = \"titanic_train.csv\"\n",
    "titanic_df = spark.read.format(\"csv\").options(inferSchema=\"true\", header=\"true\").load(file)\n",
    "titanic_df = titanic_df.dropna(how='any')\n",
    "titanic_df.show(10)\n",
    "print(titanic_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45tDK3AbDTTb"
   },
   "source": [
    "### Exercise 1.A.\n",
    "**TODO:** Calculate descriptive statistics for 'Age' and 'Fare' (see https://spark.apache.org/docs/1.6.1/api/java/org/apache/spark/sql/DataFrame.html#describe(scala.collection.Seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH4SqCVgjYzX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnmEXLrSDTTd"
   },
   "source": [
    "### Exercise 1.B.\n",
    "\n",
    "**TODO:** Check if 'Age' and 'Fare' have normal distribution (see http://spark.apache.org/docs/latest/api/java/org/apache/spark/ml/stat/KolmogorovSmirnovTest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U2RwXRejak3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LABGbwAsNJCa"
   },
   "source": [
    "### Exercise 1.C.\n",
    "\n",
    "**TODO:** Calculate Pearson correlation between the following pairs of features:  \n",
    "* 'Age' and 'Survived'\n",
    "* 'Sex' and 'Survived' *(remember about encoding 'Sex' attributes as 0s and 1s)*\n",
    "\n",
    "Which correlation is stronger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHUlmM-OjcBi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq3d-SBVDTTe"
   },
   "source": [
    "## 2. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvoN8rt8DTTe"
   },
   "source": [
    "Doc: http://spark.apache.org/docs/latest/ml-datasource.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SQQe2vGDTTf"
   },
   "source": [
    "Download data from https://github.com/apache/spark/blob/master/data/mllib/sample_libsvm_data.txt and load as DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrqDceGODTTf",
    "outputId": "056a74dd-6034-4584-9b2d-144970c3906e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(780,[127,128,129...|\n",
      "|  1.0|(780,[158,159,160...|\n",
      "|  1.0|(780,[124,125,126...|\n",
      "|  1.0|(780,[152,153,154...|\n",
      "|  1.0|(780,[151,152,153...|\n",
      "|  0.0|(780,[129,130,131...|\n",
      "|  1.0|(780,[158,159,160...|\n",
      "|  1.0|(780,[99,100,101,...|\n",
      "|  0.0|(780,[154,155,156...|\n",
      "|  0.0|(780,[127,128,129...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=SparseVector(780, {127: 51.0, 128: 159.0, 129: 253.0, 130: 159.0, 131: 50.0, 154: 48.0, 155: 238.0, 156: 252.0, 157: 252.0, 158: 252.0, 159: 237.0, 181: 54.0, 182: 227.0, 183: 253.0, 184: 252.0, 185: 239.0, 186: 233.0, 187: 252.0, 188: 57.0, 189: 6.0, 207: 10.0, 208: 60.0, 209: 224.0, 210: 252.0, 211: 253.0, 212: 252.0, 213: 202.0, 214: 84.0, 215: 252.0, 216: 253.0, 217: 122.0, 235: 163.0, 236: 252.0, 237: 252.0, 238: 252.0, 239: 253.0, 240: 252.0, 241: 252.0, 242: 96.0, 243: 189.0, 244: 253.0, 245: 167.0, 262: 51.0, 263: 238.0, 264: 253.0, 265: 253.0, 266: 190.0, 267: 114.0, 268: 253.0, 269: 228.0, 270: 47.0, 271: 79.0, 272: 255.0, 273: 168.0, 289: 48.0, 290: 238.0, 291: 252.0, 292: 252.0, 293: 179.0, 294: 12.0, 295: 75.0, 296: 121.0, 297: 21.0, 300: 253.0, 301: 243.0, 302: 50.0, 316: 38.0, 317: 165.0, 318: 253.0, 319: 233.0, 320: 208.0, 321: 84.0, 328: 253.0, 329: 252.0, 330: 165.0, 343: 7.0, 344: 178.0, 345: 252.0, 346: 240.0, 347: 71.0, 348: 19.0, 349: 28.0, 356: 253.0, 357: 252.0, 358: 195.0, 371: 57.0, 372: 252.0, 373: 252.0, 374: 63.0, 384: 253.0, 385: 252.0, 386: 195.0, 399: 198.0, 400: 253.0, 401: 190.0, 412: 255.0, 413: 253.0, 414: 196.0, 426: 76.0, 427: 246.0, 428: 252.0, 429: 112.0, 440: 253.0, 441: 252.0, 442: 148.0, 454: 85.0, 455: 252.0, 456: 230.0, 457: 25.0, 466: 7.0, 467: 135.0, 468: 253.0, 469: 186.0, 470: 12.0, 482: 85.0, 483: 252.0, 484: 223.0, 493: 7.0, 494: 131.0, 495: 252.0, 496: 225.0, 497: 71.0, 510: 85.0, 511: 252.0, 512: 145.0, 520: 48.0, 521: 165.0, 522: 252.0, 523: 173.0, 538: 86.0, 539: 253.0, 540: 225.0, 547: 114.0, 548: 238.0, 549: 253.0, 550: 162.0, 566: 85.0, 567: 252.0, 568: 249.0, 569: 146.0, 570: 48.0, 571: 29.0, 572: 85.0, 573: 178.0, 574: 225.0, 575: 253.0, 576: 223.0, 577: 167.0, 578: 56.0, 594: 85.0, 595: 252.0, 596: 252.0, 597: 252.0, 598: 229.0, 599: 215.0, 600: 252.0, 601: 252.0, 602: 252.0, 603: 196.0, 604: 130.0, 622: 28.0, 623: 199.0, 624: 252.0, 625: 252.0, 626: 253.0, 627: 252.0, 628: 252.0, 629: 233.0, 630: 145.0, 651: 25.0, 652: 128.0, 653: 252.0, 654: 253.0, 655: 252.0, 656: 141.0, 657: 37.0}))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"sample_libsvm_data.txt\"\n",
    "\n",
    "df = spark.read.format(\"libsvm\").option(\"numFeatures\", \"780\").load(file)\n",
    "df.show(10)\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1l4ZSj7hJ27W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwEFjUnbDTTg"
   },
   "source": [
    "### Exercise 2.A\n",
    "**TODO:** Load wine data from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/wine.scale\n",
    "Dataset description: http://archive.ics.uci.edu/ml/datasets/Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w71w8XBzjeXE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJn0NAMtDTTh"
   },
   "source": [
    "## 3. Classification (2p.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5B3svtjNDTTj",
    "outputId": "7a07f7cf-5946-4bbd-ca73-3bf068e60b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+----+----+---+-------+----------+--------------------+-------+-----+----+----+-------+\n",
      "|Wine|Alcohol|Malic| Ash| Acl| Mg|Phenols|Flavanoids|Nonflavanoid_phenols|Proanth|Color| Hue|  OD|Proline|\n",
      "+----+-------+-----+----+----+---+-------+----------+--------------------+-------+-----+----+----+-------+\n",
      "|   1|  14.23| 1.71|2.43|15.6|127|    2.8|      3.06|                0.28|   2.29| 5.64|1.04|3.92|   1065|\n",
      "|   1|   13.2| 1.78|2.14|11.2|100|   2.65|      2.76|                0.26|   1.28| 4.38|1.05| 3.4|   1050|\n",
      "|   1|  13.16| 2.36|2.67|18.6|101|    2.8|      3.24|                 0.3|   2.81| 5.68|1.03|3.17|   1185|\n",
      "|   1|  14.37| 1.95| 2.5|16.8|113|   3.85|      3.49|                0.24|   2.18|  7.8|0.86|3.45|   1480|\n",
      "|   1|  13.24| 2.59|2.87|21.0|118|    2.8|      2.69|                0.39|   1.82| 4.32|1.04|2.93|    735|\n",
      "|   1|   14.2| 1.76|2.45|15.2|112|   3.27|      3.39|                0.34|   1.97| 6.75|1.05|2.85|   1450|\n",
      "|   1|  14.39| 1.87|2.45|14.6| 96|    2.5|      2.52|                 0.3|   1.98| 5.25|1.02|3.58|   1290|\n",
      "|   1|  14.06| 2.15|2.61|17.6|121|    2.6|      2.51|                0.31|   1.25| 5.05|1.06|3.58|   1295|\n",
      "|   1|  14.83| 1.64|2.17|14.0| 97|    2.8|      2.98|                0.29|   1.98|  5.2|1.08|2.85|   1045|\n",
      "|   1|  13.86| 1.35|2.27|16.0| 98|   2.98|      3.15|                0.22|   1.85| 7.22|1.01|3.55|   1045|\n",
      "+----+-------+-----+----+----+---+-------+----------+--------------------+-------+-----+----+----+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "[('Wine', 'int'), ('Alcohol', 'double'), ('Malic', 'double'), ('Ash', 'double'), ('Acl', 'double'), ('Mg', 'int'), ('Phenols', 'double'), ('Flavanoids', 'double'), ('Nonflavanoid_phenols', 'double'), ('Proanth', 'double'), ('Color', 'double'), ('Hue', 'double'), ('OD', 'double'), ('Proline', 'int')]\n"
     ]
    }
   ],
   "source": [
    "file = \"wine.csv\" # https://gist.githubusercontent.com/tijptjik/9408623/raw/b237fa5848349a14a14e5d4107dc7897c21951f5/wine.csv\n",
    "\n",
    "# Remember about deleting dots from the headers of this csv file!\n",
    "winedf2 = spark.read.format(\"csv\").options(inferSchema=\"true\", header=\"true\").load(file)\n",
    "winedf2.show(10)\n",
    "print(winedf2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rjp6BHOadXUs"
   },
   "source": [
    "### Exercise 3.A\n",
    "**TODO:** \n",
    "\n",
    "Remember about deleting dots from the headers of this csv file and splitting data into train and test set\n",
    "\n",
    "\n",
    "1) Create pipeline with VectorAssembler and DecisionTreeClassifier.\n",
    "\n",
    "2) Use the pipeline to make predictions.\n",
    "\n",
    "3) Evaluate predictions using MulticlassClassificationEvaluator.\n",
    "\n",
    "4) Calculate accuracy and test error\n",
    "\n",
    "5) Print the structure of the trained decision tree (hint: use toDebugString attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTfU0f0cjhV1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF73uyZ5DTTk"
   },
   "source": [
    "### Exercise 3.B\n",
    "**TODO:** \n",
    "\n",
    "1) Extend the pipeline from the previos task with QuantileDiscretizer \n",
    "\n",
    "2) Try using a couple of different numbers of buckets, which cinfiguration gives the best results?\n",
    "\n",
    "3) Can you see any difference in the structure of the decistion tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0Ax7J2kjiQX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZ458SgIDTTk"
   },
   "source": [
    "## 4. Text classification (2p.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwzu_i7BDTTl"
   },
   "source": [
    "### Exercise 4\n",
    "**TODO:** \n",
    "Build a pipeline consisting of Tokenizer, HashingTF, IDF and StringIndexer and LogisticRegression, fit it to training data: \n",
    "http://help.sentiment140.com/for-students/\n",
    "\n",
    "What is the accuracy of this classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9QbF10DjwU5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Empty_ADZD-6-MLlib.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
